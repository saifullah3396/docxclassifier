# @package args.model_args

name: fusion_model_image_vae
model_task: autoencoding
cache_dir: ${oc.env:TORCH_FUSION_CACHE_DIR}/pretrained/
model_directory_name: ${args.model_args.name}_${args.model_args.model_config.model_constructor_args.model_name}
convert_bn_to_gn: false
remove_lora_layers: false
return_dict: True
bypass_params_creation: False 
model_config:
  model_constructor: fusion_model
  model_constructor_args:
    model_name: compvis_autoencoder
    init_args: # model config
      double_z: True
      z_channels: 3
      embed_dim: 3  # -> this turns the image final dimension to h x w x embed_dim
      image_size: 256

      model_channels:  128
      out_channels: 3
      channel_mults: [1, 2, 4]
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      in_channels: 3
      use_linear_attn: False
      attn_type: vanilla
      resamp_with_conv: True
    pretrained: True
    checkpoint: /home/ataraxia/Projects/models/compvis/klf4.pt
    checkpoint_state_dict_key: state_dict